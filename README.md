# LeetCode Daily Problem Tracker

A web application that automatically fetches and tracks daily LeetCode problems, allowing users to view problem details, solutions, and track their progress.

## Table of Contents
- [Features](#features)
- [Architecture](#architecture)
- [Technology Stack](#technology-stack)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [Development](#development)
- [Deployment](#deployment)
- [Contributing](#contributing)
- [License](#license)

## Features
- üéØ Daily LeetCode problem tracking
- üìù Detailed problem descriptions and examples
- üí° Solution tracking
- üîÑ Automatic problem fetching
- üìä Progress tracking
- üåê Modern web interface

## Architecture

### System Flow
```mermaid
graph TD
    A[Quartz Job] -->|Daily Trigger| B[LeetCode API]
    B -->|Fetch Problem| C[Save to Local Storage]
    C -->|JSON File| D[Web Application]
    D -->|Display| E[User Interface]
    E -->|View Details| F[Problem Detail Page]
    E -->|Manual Fetch| G[Fetch Button]
    G -->|Trigger| A
```

### Data Flow
```mermaid
sequenceDiagram
    participant Q as Quartz Job
    participant L as LeetCode API
    participant S as Storage
    participant W as Web App
    participant U as User

    Q->>L: Request Daily Problem
    L-->>Q: Return Problem Data
    Q->>S: Save Problem JSON
    U->>W: Access Web App
    W->>S: Read Problem Data
    W-->>U: Display Problems
    U->>W: View Problem Details
    W-->>U: Show Problem Content
```

## Technology Stack
- **Backend**: .NET 9, Blazor Server
- **Frontend**: Blazor Components, Bootstrap 5
- **Scheduling**: Quartz.NET
- **Storage**: File System (JSON)
- **API Integration**: LeetCode GraphQL API
- **Error Handling**: Polly (Retry Policy)
- **Logging**: Serilog with Elasticsearch sink
- **Monitoring**: Elasticsearch & Kibana

## Project Structure
```
LeetCodeDaily/
‚îú‚îÄ‚îÄ LeetCodeDaily.Web/           # Main web application
‚îÇ   ‚îú‚îÄ‚îÄ Components/              # Blazor components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Pages/              # Page components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Layout/             # Layout components
‚îÇ   ‚îú‚îÄ‚îÄ Services/               # Business logic services
‚îÇ   ‚îú‚îÄ‚îÄ Models/                 # Data models
‚îÇ   ‚îú‚îÄ‚îÄ Jobs/                   # Background jobs
‚îÇ   ‚îî‚îÄ‚îÄ Solutions/              # Problem solutions storage
‚îî‚îÄ‚îÄ README.md                   # Project documentation
```

## Getting Started

### Prerequisites
- .NET 9 SDK
- Visual Studio 2022 or VS Code
- Git

### Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/LeetCodeDaily.git
   ```

2. Navigate to the project directory:
   ```bash
   cd LeetCodeDaily
   ```

3. Restore dependencies:
   ```bash
   dotnet restore
   ```

4. Run the application:
   ```bash
   dotnet run --project LeetCodeDaily.Web
   ```

5. Open your browser and navigate to:
   ```
   https://localhost:7131
   ```

## Development

### Key Components
- **LeetCodeService**: Handles communication with LeetCode API
- **DailyProblemJob**: Quartz job for fetching daily problems
- **LeetCodeProblems.razor**: Main problem list page
- **LeetCodeProblemDetail.razor**: Problem detail page

### Adding New Features
1. Create feature branch
2. Implement changes
3. Add tests if applicable
4. Submit pull request

## Deployment
The application can be deployed to any environment that supports .NET 9:
- Azure App Service
- Docker containers
- Self-hosted servers

### Docker Deployment
```bash
docker build -t leetcodedaily .
docker run -p 8080:80 leetcodedaily
```

## Contributing
1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License
This project is licensed under the MIT License - see the LICENSE file for details.

# Elasticsearch v√† Kibana Setup

## Y√™u c·∫ßu
- Docker Desktop ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t
- Docker Compose ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t

## C√°ch ch·∫°y

1. Kh·ªüi ƒë·ªông c√°c container:
```bash
docker-compose up -d
```

2. Ki·ªÉm tra tr·∫°ng th√°i c√°c container:
```bash
docker-compose ps
```

3. Ki·ªÉm tra logs:
```bash
docker-compose logs -f
```

4. Truy c·∫≠p c√°c service:
- Elasticsearch: http://localhost:9200
- Kibana: http://localhost:5601

## C·∫•u h√¨nh

### Elasticsearch
- Port: 9200 (HTTP), 9300 (Transport)
- Memory: 512MB (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh trong docker-compose.yml)
- Data ƒë∆∞·ª£c l∆∞u trong volume: elasticsearch-data

### Kibana
- Port: 5601
- K·∫øt n·ªëi t·ª± ƒë·ªông v·ªõi Elasticsearch

## D·ª´ng v√† x√≥a

1. D·ª´ng c√°c container:
```bash
docker-compose down
```

2. X√≥a c·∫£ data:
```bash
docker-compose down -v
```

## Troubleshooting

1. N·∫øu Elasticsearch kh√¥ng kh·ªüi ƒë·ªông ƒë∆∞·ª£c:
```bash
docker-compose logs elasticsearch
```

2. N·∫øu Kibana kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c v·ªõi Elasticsearch:
```bash
docker-compose logs kibana
```

3. Ki·ªÉm tra memory:
```bash
docker stats
```

## Backup v√† Restore

1. Backup data:
```bash
docker run --rm --volumes-from elasticsearch -v $(pwd):/backup alpine tar cvf /backup/elasticsearch-backup.tar /usr/share/elasticsearch/data
```

2. Restore data:
```bash
docker run --rm --volumes-from elasticsearch -v $(pwd):/backup alpine sh -c "cd /usr/share/elasticsearch/data && tar xvf /backup/elasticsearch-backup.tar"
```

## Logging Configuration

### Serilog Setup
The application uses Serilog for structured logging with the following sinks:
- Elasticsearch sink for centralized log storage
- Console sink for development debugging
- File sink for local log storage

### Logging Features
- Structured logging with JSON format
- Correlation IDs for request tracking
- Log levels (Information, Warning, Error, Debug)
- Exception details with stack traces
- Request/Response logging
- Performance metrics

### Elasticsearch & Kibana Integration
The application sends logs to Elasticsearch which can be visualized in Kibana:

1. **Elasticsearch Configuration**:
   - Host: http://localhost:9200
   - Index pattern: leetcodedaily-{yyyy.MM.dd}
   - Log retention: 30 days

2. **Kibana Dashboard**:
   - Access URL: http://localhost:5601
   - Default index pattern: leetcodedaily-*
   - Pre-configured dashboards for:
     - Application errors
     - Performance metrics
     - Request patterns
     - User activity

3. **Log Fields**:
   - Timestamp
   - Log Level
   - Message
   - Exception details
   - Request path
   - User information
   - Performance metrics
   - Correlation ID

### Viewing Logs
1. Access Kibana at http://localhost:5601
2. Navigate to "Discover" section
3. Select the "leetcodedaily-*" index pattern
4. Use the search bar to filter logs
5. Create visualizations and dashboards as needed

### Logging Best Practices
- Use appropriate log levels
- Include relevant context in log messages
- Avoid logging sensitive information
- Use structured logging for better analysis
- Monitor log volume and retention 